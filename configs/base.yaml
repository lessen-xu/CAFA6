# CAFA6 Training Configuration

data:
  data_dir: "data"
  max_length: 512
  val_ratio: 0.1
  num_workers: 4

model:
  type: "esm_light"  # Use lighter model for 4060
  name: "facebook/esm2_t12_35M_UR50D"  # 35M model
  dropout: 0.2
  freeze_backbone: false

training:
  batch_size: 8  # Adjust based on GPU memory
  epochs: 10
  learning_rate: 1.0e-4
  weight_decay: 0.01
  max_grad_norm: 1.0
  
output:
  save_dir: "outputs/experiment_001"
